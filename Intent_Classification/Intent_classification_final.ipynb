{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dark-Sied/Intent_Classification/blob/master/Intent_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a_WypuUXi92e",
    "outputId": "133d026e-4236-4ff6-f21d-739bfb9640db"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout,LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bert4keras.models import build_transformer_model\n",
    "#from bert4keras.tokenizers import Tokenizer\n",
    "#config_path = '../bert/bert_config.json'\n",
    "#checkpoint_path = '../bert/bert_model.ckpt'\n",
    "#dict_path = '../bert/vocab.txt'\n",
    "#tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "#model = build_transformer_model(config_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_ids, segment_ids = tokenizer.encode(u'语言模型')\n",
    "\n",
    "#print('\\n ===== predicting =====\\n')\n",
    "#print(model.predict([np.array([token_ids]), np.array([segment_ids])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LE6wywJrN2ih"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "  df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Sentence\", \"Intent\"])\n",
    "  print(df.head())\n",
    "  intent = df[\"Intent\"]\n",
    "  unique_intent = list(set(intent))\n",
    "  sentences = list(df[\"Sentence\"])\n",
    "  \n",
    "  return (intent, unique_intent, sentences)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "tF0FQA7gjOCX",
    "outputId": "c609b42a-05da-49f5-8d11-bd670210f635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Sentence          Intent\n",
      "0       Need help pleese  commonQ.assist\n",
      "1              Need help  commonQ.assist\n",
      "2       I need some info  commonQ.assist\n",
      "3      Will you help me?  commonQ.assist\n",
      "4  What else can you do?  commonQ.assist\n"
     ]
    }
   ],
   "source": [
    "intent, unique_intent, sentences = load_dataset(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O8LLUZlokg0S",
    "outputId": "c15c21dc-2ef2-43b7-b4af-e7ee9e014091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Need help pleese', 'Need help', 'I need some info', 'Will you help me?', 'What else can you do?']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "MhrziINPGHbW",
    "outputId": "0861af1b-4b82-4c92-b8f4-b6b57bb3e380"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cklam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cklam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmNLu2YSXePb"
   },
   "outputs": [],
   "source": [
    "#define stemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-7q3iG5PKYI"
   },
   "outputs": [],
   "source": [
    "def cleaning(sentences):\n",
    "  words = []\n",
    "  for s in sentences:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
    "    w = word_tokenize(clean)\n",
    "    #stemming\n",
    "    words.append([i.lower() for i in w])\n",
    "    \n",
    "  return words  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p1j2GJgDG6qj",
    "outputId": "c7232a8e-6833-4a1d-e71a-4bc7014084a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n",
      "[['need', 'help', 'pleese'], ['need', 'help']]\n"
     ]
    }
   ],
   "source": [
    "cleaned_words = cleaning(sentences)\n",
    "print(len(cleaned_words))\n",
    "print(cleaned_words[:2])  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJCQ_YhBJW7t"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJhdIJC5Q3Q6"
   },
   "outputs": [],
   "source": [
    "def max_length(words):\n",
    "  return(len(max(words, key = len)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JWjxPGsZZJNX",
    "outputId": "b02c8f6b-d0df-4e90-fa3a-2ff730c88300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 492 and Maximum length = 28\n"
     ]
    }
   ],
   "source": [
    "word_tokenizer = create_tokenizer(cleaned_words)\n",
    "vocab_size = len(word_tokenizer.word_index) + 1\n",
    "max_length = max_length(cleaned_words)\n",
    "\n",
    "\n",
    "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0TXu2xsR8jq"
   },
   "outputs": [],
   "source": [
    "def encoding_doc(token, words):\n",
    "  return(token.texts_to_sequences(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE92Hk1Va--H"
   },
   "outputs": [],
   "source": [
    "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)\n",
    "word_index = word_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyOzLEboc4LZ"
   },
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdejoJrlc-tc"
   },
   "outputs": [],
   "source": [
    "padded_doc = padding_doc(encoded_doc, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "gDgTCS2KdI2p",
    "outputId": "ac5332cd-0a0f-4311-8db4-22df92728d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25,  77, 332,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 25,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  1,  25, 198, 181,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [ 51,  10,  77,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  8, 268,   4,  10,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3eaSIDi0dNf1",
    "outputId": "4ab6b6dd-ffa4-4061-9e9d-7a01decfa837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded docs =  (1113, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded docs = \",padded_doc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 轉成 Embedding 層的 input vector\n",
    "num_words = min(20000,len(word_index)+1)\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "for word, i in word_index.items():\n",
    "    if i >= len(word_index):\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 載入預訓模型，trainable = False 表示不重新計算\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0rXzenSpgFR"
   },
   "outputs": [],
   "source": [
    "#tokenizer with filter changed\n",
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "yNHQtkszskxr",
    "outputId": "f5babc01-89e3-4392-e8e6-c9f257de3d07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faq.biz_new': 1,\n",
       " 'faq.borrow_limit': 2,\n",
       " 'commonq.just_details': 3,\n",
       " 'commonq.bot': 4,\n",
       " 'faq.address_proof': 5,\n",
       " 'faq.apply_register': 6,\n",
       " 'faq.banking_option_missing': 7,\n",
       " 'faq.bad_service': 8,\n",
       " 'faq.approval_time': 9,\n",
       " 'faq.aadhaar_missing': 10,\n",
       " 'faq.biz_category_missing': 11,\n",
       " 'commonq.wait': 12,\n",
       " 'faq.biz_simpler': 13,\n",
       " 'commonq.how': 14,\n",
       " 'commonq.name': 15,\n",
       " 'commonq.assist': 16,\n",
       " 'faq.application_process': 17,\n",
       " 'faq.borrow_use': 18,\n",
       " 'commonq.not_giving': 19,\n",
       " 'contact.contact': 20,\n",
       " 'commonq.query': 21}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OOx9qdBto1-"
   },
   "outputs": [],
   "source": [
    "encoded_output = encoding_doc(output_tokenizer, intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_5Lv5PiyG-z"
   },
   "outputs": [],
   "source": [
    "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dpM86WrVQlx5",
    "outputId": "71ff52a6-b3d0-4b5c-850d-5dc0a56c8aa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1113, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD3QN-RPzfet"
   },
   "outputs": [],
   "source": [
    "def one_hot(encode):\n",
    "  o = OneHotEncoder(sparse = False)\n",
    "  return(o.fit_transform(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6wP_Xed7RNR"
   },
   "outputs": [],
   "source": [
    "output_one_hot = one_hot(encoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A6HVslLTHgOM",
    "outputId": "752962df-02d8-409b-fb8f-adb06227161d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1113, 21)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqABUESD7xi9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8P4HTz6A4E-"
   },
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7E0uhC2OCtTx",
    "outputId": "6ce0e215-aa3f-43f1-ba5a-0b584b25a35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (890, 28) and train_Y = (890, 21)\n",
      "Shape of val_X = (223, 28) and val_Y = (223, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5BU_x74DNEb"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, max_length):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, 100, input_length = max_length, trainable = False, weights=[embedding_matrix]))\n",
    "#  model.add(Embedding(vocab_size, 100, input_length = max_length, trainable = False))\n",
    "  model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "  model.add(Bidirectional(LSTM(50)))\n",
    "#   model.add(LSTM(128))\n",
    "  model.add(Dense(32, activation = \"relu\"))\n",
    "  model.add(LayerNormalization())\n",
    "  model.add(Dropout(0.3))\n",
    "#  model.add(Dense(32, activation = \"relu\"))\n",
    "#  model.add(LayerNormalization())\n",
    "#  model.add(Dropout(0.3))\n",
    "  model.add(Dense(21, activation = \"softmax\"))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "f-NvE0P7MFCe",
    "outputId": "8f07056b-579e-4c15-e1af-bdfa8f681e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 28, 100)           49200     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 28, 200)           160800    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 314,389\n",
      "Trainable params: 265,189\n",
      "Non-trainable params: 49,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, max_length)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adamax\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6834
    },
    "colab_type": "code",
    "id": "_r-dxm2sMQ-d",
    "outputId": "3c37b4f8-fc4e-4c82-ab46-2aa1d8b47ffd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 890 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "768/890 [========================>.....] - ETA: 0s - loss: 2.8274 - accuracy: 0.1693\n",
      "Epoch 00001: val_loss improved from inf to 2.19133, saving model to model.h5\n",
      "890/890 [==============================] - 3s 4ms/sample - loss: 2.7596 - accuracy: 0.1831 - val_loss: 2.1913 - val_accuracy: 0.4215\n",
      "Epoch 2/100\n",
      "768/890 [========================>.....] - ETA: 0s - loss: 1.9975 - accuracy: 0.4349\n",
      "Epoch 00002: val_loss improved from 2.19133 to 1.75076, saving model to model.h5\n",
      "890/890 [==============================] - 1s 573us/sample - loss: 1.9818 - accuracy: 0.4416 - val_loss: 1.7508 - val_accuracy: 0.5426\n",
      "Epoch 3/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 1.6087 - accuracy: 0.6162\n",
      "Epoch 00003: val_loss improved from 1.75076 to 1.53985, saving model to model.h5\n",
      "890/890 [==============================] - 0s 554us/sample - loss: 1.5850 - accuracy: 0.6236 - val_loss: 1.5398 - val_accuracy: 0.6188\n",
      "Epoch 4/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 1.3387 - accuracy: 0.6988\n",
      "Epoch 00004: val_loss improved from 1.53985 to 1.30849, saving model to model.h5\n",
      "890/890 [==============================] - 1s 565us/sample - loss: 1.3246 - accuracy: 0.7000 - val_loss: 1.3085 - val_accuracy: 0.7085\n",
      "Epoch 5/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 1.1255 - accuracy: 0.7588\n",
      "Epoch 00005: val_loss improved from 1.30849 to 1.17329, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 1.1238 - accuracy: 0.7539 - val_loss: 1.1733 - val_accuracy: 0.7803\n",
      "Epoch 6/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.9708 - accuracy: 0.7925\n",
      "Epoch 00006: val_loss improved from 1.17329 to 1.05542, saving model to model.h5\n",
      "890/890 [==============================] - 0s 548us/sample - loss: 0.9890 - accuracy: 0.7921 - val_loss: 1.0554 - val_accuracy: 0.8161\n",
      "Epoch 7/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.8889 - accuracy: 0.8225\n",
      "Epoch 00007: val_loss improved from 1.05542 to 0.97566, saving model to model.h5\n",
      "890/890 [==============================] - 0s 547us/sample - loss: 0.8745 - accuracy: 0.8281 - val_loss: 0.9757 - val_accuracy: 0.7892\n",
      "Epoch 8/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.7780 - accuracy: 0.8475\n",
      "Epoch 00008: val_loss improved from 0.97566 to 0.87641, saving model to model.h5\n",
      "890/890 [==============================] - 0s 549us/sample - loss: 0.7749 - accuracy: 0.8483 - val_loss: 0.8764 - val_accuracy: 0.8296\n",
      "Epoch 9/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.6870 - accuracy: 0.8800\n",
      "Epoch 00009: val_loss improved from 0.87641 to 0.83400, saving model to model.h5\n",
      "890/890 [==============================] - 1s 563us/sample - loss: 0.7088 - accuracy: 0.8719 - val_loss: 0.8340 - val_accuracy: 0.8027\n",
      "Epoch 10/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.6125 - accuracy: 0.8863\n",
      "Epoch 00010: val_loss improved from 0.83400 to 0.76908, saving model to model.h5\n",
      "890/890 [==============================] - 0s 554us/sample - loss: 0.6046 - accuracy: 0.8888 - val_loss: 0.7691 - val_accuracy: 0.8296\n",
      "Epoch 11/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.5731 - accuracy: 0.9062\n",
      "Epoch 00011: val_loss improved from 0.76908 to 0.71864, saving model to model.h5\n",
      "890/890 [==============================] - 0s 546us/sample - loss: 0.5712 - accuracy: 0.9056 - val_loss: 0.7186 - val_accuracy: 0.8430\n",
      "Epoch 12/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.5123 - accuracy: 0.9150\n",
      "Epoch 00012: val_loss improved from 0.71864 to 0.70650, saving model to model.h5\n",
      "890/890 [==============================] - 0s 551us/sample - loss: 0.5211 - accuracy: 0.9146 - val_loss: 0.7065 - val_accuracy: 0.8475\n",
      "Epoch 13/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.4819 - accuracy: 0.9050\n",
      "Epoch 00013: val_loss improved from 0.70650 to 0.66377, saving model to model.h5\n",
      "890/890 [==============================] - 1s 564us/sample - loss: 0.4718 - accuracy: 0.9101 - val_loss: 0.6638 - val_accuracy: 0.8341\n",
      "Epoch 14/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.4137 - accuracy: 0.9438\n",
      "Epoch 00014: val_loss improved from 0.66377 to 0.63949, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 0.4139 - accuracy: 0.9404 - val_loss: 0.6395 - val_accuracy: 0.8475\n",
      "Epoch 15/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.3718 - accuracy: 0.9413\n",
      "Epoch 00015: val_loss improved from 0.63949 to 0.59207, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 0.3635 - accuracy: 0.9461 - val_loss: 0.5921 - val_accuracy: 0.8610\n",
      "Epoch 16/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9538\n",
      "Epoch 00016: val_loss improved from 0.59207 to 0.57023, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 0.3259 - accuracy: 0.9539 - val_loss: 0.5702 - val_accuracy: 0.8655\n",
      "Epoch 17/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.3392 - accuracy: 0.9500\n",
      "Epoch 00017: val_loss did not improve from 0.57023\n",
      "890/890 [==============================] - 0s 536us/sample - loss: 0.3327 - accuracy: 0.9528 - val_loss: 0.5899 - val_accuracy: 0.8655\n",
      "Epoch 18/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9538\n",
      "Epoch 00018: val_loss did not improve from 0.57023\n",
      "890/890 [==============================] - 0s 531us/sample - loss: 0.3065 - accuracy: 0.9551 - val_loss: 0.6205 - val_accuracy: 0.8610\n",
      "Epoch 19/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.2683 - accuracy: 0.9700\n",
      "Epoch 00019: val_loss improved from 0.57023 to 0.55652, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 0.2700 - accuracy: 0.9697 - val_loss: 0.5565 - val_accuracy: 0.8744\n",
      "Epoch 20/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.2579 - accuracy: 0.9613\n",
      "Epoch 00020: val_loss improved from 0.55652 to 0.53726, saving model to model.h5\n",
      "890/890 [==============================] - 0s 561us/sample - loss: 0.2573 - accuracy: 0.9607 - val_loss: 0.5373 - val_accuracy: 0.8879\n",
      "Epoch 21/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.2259 - accuracy: 0.9700\n",
      "Epoch 00021: val_loss improved from 0.53726 to 0.53536, saving model to model.h5\n",
      "890/890 [==============================] - 0s 557us/sample - loss: 0.2312 - accuracy: 0.9697 - val_loss: 0.5354 - val_accuracy: 0.8700\n",
      "Epoch 22/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.2166 - accuracy: 0.9725\n",
      "Epoch 00022: val_loss improved from 0.53536 to 0.50847, saving model to model.h5\n",
      "890/890 [==============================] - 0s 557us/sample - loss: 0.2143 - accuracy: 0.9753 - val_loss: 0.5085 - val_accuracy: 0.8879\n",
      "Epoch 23/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.2034 - accuracy: 0.9712\n",
      "Epoch 00023: val_loss improved from 0.50847 to 0.47563, saving model to model.h5\n",
      "890/890 [==============================] - 0s 554us/sample - loss: 0.2031 - accuracy: 0.9708 - val_loss: 0.4756 - val_accuracy: 0.8834\n",
      "Epoch 24/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.1889 - accuracy: 0.9812\n",
      "Epoch 00024: val_loss did not improve from 0.47563\n",
      "890/890 [==============================] - 0s 530us/sample - loss: 0.1839 - accuracy: 0.9820 - val_loss: 0.5340 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.1778 - accuracy: 0.9787\n",
      "Epoch 00025: val_loss did not improve from 0.47563\n",
      "890/890 [==============================] - 0s 530us/sample - loss: 0.1789 - accuracy: 0.9787 - val_loss: 0.4939 - val_accuracy: 0.8879\n",
      "Epoch 26/100\n",
      "800/890 [=========================>....] - ETA: 0s - loss: 0.1676 - accuracy: 0.9825\n",
      "Epoch 00026: val_loss did not improve from 0.47563\n",
      "890/890 [==============================] - 0s 525us/sample - loss: 0.1739 - accuracy: 0.9809 - val_loss: 0.5298 - val_accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "hist = model.fit(train_X, train_Y, epochs = 100, batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjXKos8ocXvw"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text) # English: 'Where are you?'\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSTEzrlzcuya"
   },
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  pos(text)\n",
    "  clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(clean)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
    "  print(test_word)\n",
    "  #Check for unknown words\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    " \n",
    "  x = padding_doc(test_ls, max_length)\n",
    "  \n",
    "  pred = model.predict_proba(x)\n",
    "  \n",
    "  \n",
    "  return pred\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1ddofshmdzK"
   },
   "outputs": [],
   "source": [
    "def get_final_output(pred, classes):\n",
    "  predictions = pred[0]\n",
    " \n",
    "  classes = np.array(classes)\n",
    "  ids = np.argsort(-predictions)\n",
    "  classes = classes[ids]\n",
    "  predictions = -np.sort(-predictions)\n",
    " \n",
    "  for i in range(pred.shape[1]):\n",
    "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('word_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(word_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "23VpGuihMdEU",
    "outputId": "cd36c932-0fb0-4166-92ae-546a7676e645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can can AUX MD aux Xxx True True\n",
      "you you PRON PRP nsubj xxx True True\n",
      "help help VERB VB ROOT xxxx True False\n",
      "me I PRON PRP dobj xx True True\n",
      "? ? PUNCT . punct ? False False\n",
      "['can', 'you', 'help', 'me']\n",
      "commonQ.assist has confidence = 0.65746045\n",
      "commonQ.name has confidence = 0.06545326\n",
      "commonQ.how has confidence = 0.034884408\n",
      "faq.bad_service has confidence = 0.030022996\n",
      "commonQ.just_details has confidence = 0.026091795\n",
      "faq.borrow_limit has confidence = 0.02516772\n",
      "faq.aadhaar_missing has confidence = 0.023635486\n",
      "faq.application_process has confidence = 0.021200769\n",
      "commonQ.query has confidence = 0.02079014\n",
      "commonQ.not_giving has confidence = 0.017898811\n",
      "commonQ.wait has confidence = 0.015623264\n",
      "faq.borrow_use has confidence = 0.014280699\n",
      "faq.biz_simpler has confidence = 0.011900881\n",
      "faq.banking_option_missing has confidence = 0.010449684\n",
      "faq.biz_category_missing has confidence = 0.008156389\n",
      "faq.apply_register has confidence = 0.005921877\n",
      "commonQ.bot has confidence = 0.0028822846\n",
      "faq.address_proof has confidence = 0.002727898\n",
      "faq.approval_time has confidence = 0.0022368357\n",
      "contact.contact has confidence = 0.0020305733\n",
      "faq.biz_new has confidence = 0.0011837905\n"
     ]
    }
   ],
   "source": [
    "text = \"Can you help me?\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKUBDT36IHKO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what what PRON WP attr xxxx True True\n",
      "is be AUX VBZ ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "status status NOUN NN nsubj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "machine machine NOUN NN pobj xxxx True False\n",
      "['what', 'is', 'the', 'status', 'of', 'machine']\n",
      "commonQ.bot has confidence = 0.44582468\n",
      "faq.apply_register has confidence = 0.25063354\n",
      "contact.contact has confidence = 0.08918841\n",
      "faq.application_process has confidence = 0.052796543\n",
      "commonQ.query has confidence = 0.02955908\n",
      "commonQ.name has confidence = 0.025358351\n",
      "commonQ.how has confidence = 0.016818201\n",
      "faq.biz_new has confidence = 0.013923896\n",
      "faq.approval_time has confidence = 0.013074705\n",
      "faq.bad_service has confidence = 0.010916483\n",
      "commonQ.not_giving has confidence = 0.009460566\n",
      "faq.address_proof has confidence = 0.008145311\n",
      "faq.borrow_use has confidence = 0.006877996\n",
      "commonQ.assist has confidence = 0.006130393\n",
      "commonQ.wait has confidence = 0.0051999525\n",
      "faq.biz_simpler has confidence = 0.0051171454\n",
      "commonQ.just_details has confidence = 0.0030393437\n",
      "faq.borrow_limit has confidence = 0.0024880916\n",
      "faq.aadhaar_missing has confidence = 0.0023510554\n",
      "faq.banking_option_missing has confidence = 0.0016290855\n",
      "faq.biz_category_missing has confidence = 0.0014671022\n"
     ]
    }
   ],
   "source": [
    "text = \"what is the status of machine\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How how ADV WRB advmod Xxx True True\n",
      "to to PART TO aux xx True True\n",
      "subscribe subscribe VERB VB ROOT xxxx True False\n",
      "a a DET DT det x True True\n",
      "IaaS IaaS PROPN NNP compound XxxX True False\n",
      "resource resource NOUN NN dobj xxxx True False\n",
      "['how', 'to', 'subscribe', 'a', 'iaas', 'resource']\n",
      "faq.application_process has confidence = 0.38295612\n",
      "commonQ.query has confidence = 0.20202105\n",
      "faq.apply_register has confidence = 0.19973065\n",
      "commonQ.bot has confidence = 0.066315725\n",
      "commonQ.how has confidence = 0.05262089\n",
      "commonQ.assist has confidence = 0.015372348\n",
      "contact.contact has confidence = 0.01315653\n",
      "faq.bad_service has confidence = 0.012977205\n",
      "faq.approval_time has confidence = 0.012356449\n",
      "commonQ.name has confidence = 0.0089979945\n",
      "commonQ.not_giving has confidence = 0.007391835\n",
      "faq.biz_simpler has confidence = 0.0049456125\n",
      "faq.address_proof has confidence = 0.003961111\n",
      "commonQ.wait has confidence = 0.0035287107\n",
      "faq.biz_new has confidence = 0.0035102002\n",
      "faq.aadhaar_missing has confidence = 0.00257997\n",
      "commonQ.just_details has confidence = 0.0025494834\n",
      "faq.borrow_limit has confidence = 0.0025070042\n",
      "faq.borrow_use has confidence = 0.0011730397\n",
      "faq.biz_category_missing has confidence = 0.00085786066\n",
      "faq.banking_option_missing has confidence = 0.00049022445\n"
     ]
    }
   ],
   "source": [
    "text = \"How to subscribe a IaaS resource\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Really really ADV RB advmod Xxxxx True True\n",
      "bad bad ADJ JJ amod xxx True False\n",
      "support support NOUN NN ROOT xxxx True False\n",
      "['really', 'bad', 'support']\n",
      "faq.bad_service has confidence = 0.40887183\n",
      "faq.aadhaar_missing has confidence = 0.26385894\n",
      "faq.application_process has confidence = 0.05557092\n",
      "commonQ.name has confidence = 0.049335055\n",
      "commonQ.wait has confidence = 0.047366463\n",
      "commonQ.assist has confidence = 0.022716876\n",
      "commonQ.how has confidence = 0.022009714\n",
      "commonQ.not_giving has confidence = 0.020639041\n",
      "commonQ.query has confidence = 0.01553854\n",
      "faq.borrow_limit has confidence = 0.0151531035\n",
      "faq.biz_category_missing has confidence = 0.012907332\n",
      "commonQ.bot has confidence = 0.011364317\n",
      "commonQ.just_details has confidence = 0.010146258\n",
      "faq.borrow_use has confidence = 0.010041847\n",
      "faq.address_proof has confidence = 0.010033593\n",
      "faq.banking_option_missing has confidence = 0.007573587\n",
      "faq.biz_simpler has confidence = 0.00617479\n",
      "faq.biz_new has confidence = 0.0036256227\n",
      "faq.approval_time has confidence = 0.0034237711\n",
      "faq.apply_register has confidence = 0.0032762084\n",
      "contact.contact has confidence = 0.0003721079\n"
     ]
    }
   ],
   "source": [
    "text = \"Really bad support\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What what PRON WP attr Xxxx True True\n",
      "is be AUX VBZ ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "status status NOUN NN nsubj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "PVM20210607 pvm20210607 NOUN NN pobj XXXdddd False False\n",
      "['what', 'is', 'the', 'status', 'of', 'pvm20210607']\n",
      "contact.contact has confidence = 0.428287\n",
      "faq.application_process has confidence = 0.14621717\n",
      "commonQ.name has confidence = 0.107909255\n",
      "faq.apply_register has confidence = 0.07806759\n",
      "commonQ.query has confidence = 0.035805337\n",
      "commonQ.how has confidence = 0.0357539\n",
      "commonQ.not_giving has confidence = 0.027166702\n",
      "commonQ.bot has confidence = 0.024286345\n",
      "faq.borrow_limit has confidence = 0.020852601\n",
      "commonQ.assist has confidence = 0.018779764\n",
      "faq.biz_simpler has confidence = 0.01683103\n",
      "faq.approval_time has confidence = 0.011606105\n",
      "faq.address_proof has confidence = 0.011262473\n",
      "faq.bad_service has confidence = 0.009746549\n",
      "commonQ.just_details has confidence = 0.008879144\n",
      "commonQ.wait has confidence = 0.005502616\n",
      "faq.biz_new has confidence = 0.00409557\n",
      "faq.banking_option_missing has confidence = 0.0037963414\n",
      "faq.biz_category_missing has confidence = 0.0030169091\n",
      "faq.borrow_use has confidence = 0.0014037398\n",
      "faq.aadhaar_missing has confidence = 0.0007338581\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the status of PVM20210607\"\n",
    "pred = predictions(text)\n",
    "get_final_output(pred, unique_intent)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Intent_classification_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
